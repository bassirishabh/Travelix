{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headers loaded.. plotly plotting set..\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as seab\n",
    "import pickle\n",
    "print('headers loaded.. plotly plotting set..')\n",
    "\n",
    "# Normalize function- to normalize values for review score and tip score//\n",
    "def normalize(x, new_min = 0, new_max = 100):\n",
    "    output = []\n",
    "    old_min, old_max = min(x), max(x)\n",
    "\n",
    "    for iter_val in x:\n",
    "        val = (new_max - new_min) / (old_max - old_min) * (iter_val - old_min) + new_min\n",
    "        output.append(val)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframes for google colab\n",
    "# import json\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# reviews_path = \"/content/drive/MyDrive/Course Work/SEM2/Info Storage and Retrieval/project/yelp_dataset/yelp_academic_dataset_review.csv\"\n",
    "# business_path = \"/content/drive/MyDrive/Course Work/SEM2/Info Storage and Retrieval/project/yelp_dataset/yelp_academic_dataset_business.csv\"\n",
    "# user_path = \"/content/drive/MyDrive/Course Work/SEM2/Info Storage and Retrieval/project/yelp_dataset/yelp_academic_dataset_user.csv\"\n",
    "\n",
    "# reviews_df = pd.read_csv(reviews_path)\n",
    "# user_df = pd.read_csv(user_path)\n",
    "# business_df = pd.read_csv(business_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe for Local VS Code\n",
    "reviews_df = pd.read_csv('yelp_academic_dataset_review.csv')\n",
    "# user_df = pd.read_csv('yelp_academic_dataset_user.csv')\n",
    "business_df = pd.read_csv('yelp_academic_dataset_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PA', 'FL', 'TN', 'IN', 'MO', 'LA', 'AZ', 'NJ', 'NV', 'AB']\n"
     ]
    }
   ],
   "source": [
    "# Get Top Ten States\n",
    "business_df = business_df.dropna(subset=['categories'])\n",
    "unique_states = business_df['state'].unique()\n",
    "state_map = dict()\n",
    "for s in unique_states:\n",
    "  state_map[s] = business_df[business_df['state'] == s].shape[0]\n",
    "# 'CA' 'MO' 'AZ' 'PA' 'TN' 'FL' 'IN' 'LA' 'AB' 'NV' 'ID' 'DE' 'IL' 'NJ' 'NC' 'CO' 'WA' 'HI' 'UT' 'TX' 'MT' 'MI' 'SD' 'XMS' 'MA' 'VI' 'VT'\n",
    "top_states = [state[0] for state in sorted(sorted(state_map.items(), key=lambda x: x[1], reverse=True), key=lambda x: x[1], reverse=True)[:10]]\n",
    "print(top_states)\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "hotel_state_df_map = {}\n",
    "restaurent_state_df_map = {}\n",
    "\n",
    "# Creating mask for Hotels & Travel\n",
    "hotel_mask = business_df['categories'].str.contains('Hotels & Travel')\n",
    "hotel_df = business_df[hotel_mask]\n",
    "\n",
    "# Creating mask for Restaurents\n",
    "restaurent_mask = business_df['categories'].str.contains('Restaurants')\n",
    "restaurent_df = business_df[restaurent_mask]\n",
    "\n",
    "for state in top_states:\n",
    "    df_name = f'business_df_{state}'\n",
    "\n",
    "    hotel_state_df = hotel_df[hotel_df['state'] == state]\n",
    "    restaurent_state_df = restaurent_df[restaurent_df['state'] == state]\n",
    "\n",
    "    exec(f\"{df_name} = hotel_state_df\")\n",
    "    # add the dataframe to the dictionary with the state abbreviation as the key\n",
    "    hotel_state_df_map[state] = hotel_state_df\n",
    "\n",
    "    exec(f\"{df_name} = restaurent_state_df\")\n",
    "    # add the dataframe to the dictionary with the state abbreviation as the key\n",
    "    restaurent_state_df_map[state] = restaurent_state_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Ratings Matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class Recommendations:\n",
    "  class Business:\n",
    "    def __init__(self, name, address, city, state, postal_code, stars):\n",
    "      self.name = name\n",
    "      self.address = address\n",
    "      self.city = city\n",
    "      self.state = state\n",
    "      self.postal_code = postal_code\n",
    "      self.stars = stars\n",
    "  \n",
    "  def __init__(self, business_df):\n",
    "    self.business_df = business_df\n",
    "    self.rating_mat = []\n",
    "    self.user_num_to_user_hash_dict = dict()\n",
    "    self.user_hash_to_user_num_dict = dict()\n",
    "    self.business_num_to_business_hash_dict = dict()\n",
    "    self.business_hash_to_business_num_dict = dict()\n",
    "    self.business_recommendations = []\n",
    "    self.business_popularity = []\n",
    "    self.calculateRatingMatrix()\n",
    "    self.nonPersonalizedRecommendations()\n",
    "  \n",
    "  def calculateRatingMatrix(self):\n",
    "    print(\"Calculating rating matrix...\")\n",
    "    business_list = list(self.business_df['business_id'])\n",
    "    reviews_df_updated = reviews_df[reviews_df['business_id'].isin(business_list)]\n",
    "\n",
    "    unique_business_id = reviews_df_updated['business_id'].unique()\n",
    "    unique_user_id = reviews_df_updated['user_id'].unique()\n",
    "\n",
    "    j = 0\n",
    "    for u in unique_user_id:\n",
    "        self.user_hash_to_user_num_dict[u] = j\n",
    "        self.user_num_to_user_hash_dict[j] = u\n",
    "        j += 1\n",
    "\n",
    "    j = 0\n",
    "    for i in unique_business_id:\n",
    "        self.business_hash_to_business_num_dict[i] = j\n",
    "        self.business_num_to_business_hash_dict[j] = i\n",
    "        j += 1\n",
    "\n",
    "    # Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "    user_list = reviews_df_updated['user_id'].values\n",
    "    movie_list = reviews_df_updated['business_id'].values\n",
    "    for j in range(len(reviews_df_updated)):\n",
    "        user_list[j] = self.user_hash_to_user_num_dict[user_list[j]]\n",
    "        movie_list[j] = self.business_hash_to_business_num_dict[movie_list[j]]\n",
    "    reviews_df_updated['user_id'] = user_list\n",
    "    reviews_df_updated['business_id'] = movie_list\n",
    "\n",
    "    num_user = len(reviews_df_updated['user_id'].unique())\n",
    "    num_movie = len(reviews_df_updated['business_id'].unique())\n",
    "\n",
    "    self.ratings_mat = coo_matrix((reviews_df_updated['stars'].values, (reviews_df_updated['user_id'].values, reviews_df_updated['business_id'].values)), shape=(num_user, num_movie)).astype(float).toarray()\n",
    "  \n",
    "  def nonPersonalizedRecommendations(self):\n",
    "    print(\"Calculating NPR...\")\n",
    "    n = len(self.ratings_mat) # number of users\n",
    "    m = len(self.ratings_mat[0]) # number of movies\n",
    "\n",
    "    # Creating popularity array - size number of movies\n",
    "    self.business_popularity = np.zeros((m,))\n",
    "    self.business_popularity = self.ratings_mat.sum(axis=0) # claculating the popularity of each movie by summing the values in each column\n",
    "\n",
    "    self.business_recommendations = np.zeros((n, 50), dtype=np.int32)\n",
    "\n",
    "    for u in range(self.ratings_mat.shape[0]):\n",
    "      business_unvisited = np.where(self.ratings_mat[u] == 0)[0]\n",
    "      unwatched_popularity = self.business_popularity[business_unvisited]\n",
    "      # Sort the unwatched movies according to popularity and fetch top 50 to recommend\n",
    "      self.business_recommendations[u] = business_unvisited[np.argsort(unwatched_popularity)[::-1]][:50]\n",
    "\n",
    "    # print(\"Non personalized recommendations for first User:\")\n",
    "    # for i in range(5):\n",
    "    #   business_hash = self.getBusinessHashFromBusinessNum(self.business_recommendations[0,i])\n",
    "    #   business = self.getBusinessInfo(business_hash)\n",
    "    #   print(f\"Rank {i+1}: Business {self.business_recommendations[0,i]} - Name: {business.name} - state: {business.state} - stars: {business.stars}  - Popularity {business_popularity[self.business_recommendations[0,i]]}\")\n",
    "\n",
    "  def getNPRForuUser(self, user_num):\n",
    "    print(f\"Non personalized recommendations for User {user_num}:\")\n",
    "    for i in range(5):\n",
    "      business_hash = self.getBusinessHashFromBusinessNum(self.business_recommendations[0,i])\n",
    "      business = self.getBusinessInfo(business_hash)\n",
    "      print(f\"Rank {i+1}: Business {self.business_recommendations[0,i]} - Name: {business.name} - state: {business.state} - stars: {business.stars}  - Popularity {self.business_popularity[self.business_recommendations[0,i]]}\")\n",
    "\n",
    "\n",
    "  def getUserHashFromUserNum(self, user_num):\n",
    "    return self.user_num_to_user_hash_dict[user_num]\n",
    "\n",
    "  def getUserNumFromUserHash(self, user_hash):\n",
    "    return self.user_hash_to_user_num_dict[user_hash]\n",
    "\n",
    "  def getBusinessHashFromBusinessNum(self, business_num):\n",
    "    return self.business_num_to_business_hash_dict[business_num]\n",
    "\n",
    "  def getBusinessNumFromBusinessHash(self, business_hash):\n",
    "    return self.business_hash_to_business_num_dict[business_hash]\n",
    "  \n",
    "  def getBusinessInfo(self, business_hash):\n",
    "    bus_df = self.business_df[self.business_df['business_id'] == business_hash].iloc[0]\n",
    "    return self.Business(bus_df['name'], bus_df['address'], bus_df['city'], bus_df['state'], bus_df['postal_code'], bus_df['stars'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rating matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/y5cvt00j367c_9w3d96w_y800000gn/T/ipykernel_15302/3258575506.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df_updated['user_id'] = user_list\n",
      "/var/folders/9r/y5cvt00j367c_9w3d96w_y800000gn/T/ipykernel_15302/3258575506.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df_updated['business_id'] = movie_list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n",
      "Calculating rating matrix...\n",
      "Calculating NPR...\n"
     ]
    }
   ],
   "source": [
    "# PA_Hotel_Recommendation = Recommendations(hotel_state_df_map['PA'])\n",
    "# FL_Hotel_Recommendation = Recommendations(hotel_state_df_map['FL'])\n",
    "# TN_Hotel_Recommendation = Recommendations(hotel_state_df_map['TN'])\n",
    "# IN_Hotel_Recommendation = Recommendations(hotel_state_df_map['IN'])\n",
    "# MO_Hotel_Recommendation = Recommendations(hotel_state_df_map['MO'])\n",
    "# LA_Hotel_Recommendation = Recommendations(hotel_state_df_map['LA'])\n",
    "# AZ_Hotel_Recommendation = Recommendations(hotel_state_df_map['AZ'])\n",
    "# NJ_Hotel_Recommendation = Recommendations(hotel_state_df_map['NJ'])\n",
    "# NV_Hotel_Recommendation = Recommendations(hotel_state_df_map['NV'])\n",
    "# AB_Hotel_Recommendation = Recommendations(hotel_state_df_map['AB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully saved to FL_Hotel_Recommendation.pkl\n",
      "Object successfully saved to TN_Hotel_Recommendation.pkl\n",
      "Object successfully saved to IN_Hotel_Recommendation.pkl\n",
      "Object successfully saved to MO_Hotel_Recommendation.pkl\n",
      "Object successfully saved to LA_Hotel_Recommendation.pkl\n",
      "Object successfully saved to AZ_Hotel_Recommendation.pkl\n",
      "Object successfully saved to NJ_Hotel_Recommendation.pkl\n",
      "Object successfully saved to NV_Hotel_Recommendation.pkl\n",
      "Object successfully saved to AB_Hotel_Recommendation.pkl\n"
     ]
    }
   ],
   "source": [
    "# with open('PA_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(PA_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to PA_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('FL_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(FL_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to FL_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('TN_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(TN_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to TN_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('IN_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(IN_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to IN_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('MO_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(MO_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to MO_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('LA_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(LA_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to LA_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('AZ_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(AZ_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to AZ_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('NJ_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(NJ_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to NJ_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('NV_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(NV_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to NV_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('AB_Hotel_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(AB_Hotel_Recommendation, file)\n",
    "# print(\"Object successfully saved to AB_Hotel_Recommendation.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully loaded from PA_Hotel_Recommendation.pkl\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# with open('PA_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     PA_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from PA_Hotel_Recommendation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2file as bz2\n",
    "\n",
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File(title + \".pbz2\", \"w\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "compressed_pickle(\"PA_Hotel_Recommendation\", PA_Hotel_Recommendation)\n",
    "compressed_pickle(\"FL_Hotel_Recommendation\", FL_Hotel_Recommendation)\n",
    "compressed_pickle(\"TN_Hotel_Recommendation\", TN_Hotel_Recommendation)\n",
    "compressed_pickle(\"IN_Hotel_Recommendation\", IN_Hotel_Recommendation)\n",
    "compressed_pickle(\"MO_Hotel_Recommendation\", MO_Hotel_Recommendation)\n",
    "compressed_pickle(\"LA_Hotel_Recommendation\", LA_Hotel_Recommendation)\n",
    "compressed_pickle(\"AZ_Hotel_Recommendation\", AZ_Hotel_Recommendation)\n",
    "compressed_pickle(\"NJ_Hotel_Recommendation\", NJ_Hotel_Recommendation)\n",
    "compressed_pickle(\"NV_Hotel_Recommendation\", NV_Hotel_Recommendation)\n",
    "compressed_pickle(\"AB_Hotel_Recommendation\", AB_Hotel_Recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, \"rb\")\n",
    "    data = pickle.load(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA_Hotel_Recommendation = decompress_pickle(\"PA_Hotel_Recommendation.pbz2\")\n",
    "FL_Hotel_Recommendation = decompress_pickle(\"FL_Hotel_Recommendation.pbz2\")\n",
    "TN_Hotel_Recommendation = decompress_pickle(\"TN_Hotel_Recommendation.pbz2\")\n",
    "IN_Hotel_Recommendation = decompress_pickle(\"IN_Hotel_Recommendation.pbz2\")\n",
    "MO_Hotel_Recommendation = decompress_pickle(\"MO_Hotel_Recommendation.pbz2\")\n",
    "LA_Hotel_Recommendation = decompress_pickle(\"LA_Hotel_Recommendation.pbz2\")\n",
    "AZ_Hotel_Recommendation = decompress_pickle(\"AZ_Hotel_Recommendation.pbz2\")\n",
    "NJ_Hotel_Recommendation = decompress_pickle(\"NJ_Hotel_Recommendation.pbz2\")\n",
    "NV_Hotel_Recommendation = decompress_pickle(\"NV_Hotel_Recommendation.pbz2\")\n",
    "AB_Hotel_Recommendation = decompress_pickle(\"AB_Hotel_Recommendation.pbz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully loaded from PA_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from FL_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from TN_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from IN_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from MO_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from LA_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from AZ_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from NJ_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from NV_Hotel_Recommendation.pkl\n",
      "Object successfully loaded from AB_Hotel_Recommendation.pkl\n"
     ]
    }
   ],
   "source": [
    "# with open('PA_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     PA_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from PA_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('FL_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     FL_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from FL_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('TN_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     TN_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from TN_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('IN_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     IN_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from IN_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('MO_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     MO_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from MO_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('LA_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     LA_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from LA_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('AZ_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     AZ_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from AZ_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('NJ_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     NJ_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from NJ_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('NV_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     NV_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from NV_Hotel_Recommendation.pkl\")\n",
    "\n",
    "# with open('AB_Hotel_Recommendation.pkl', 'rb') as file:\n",
    "#     AB_Hotel_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from AB_Hotel_Recommendation.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rating matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/y5cvt00j367c_9w3d96w_y800000gn/T/ipykernel_9599/3258575506.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df_updated['user_id'] = user_list\n",
      "/var/folders/9r/y5cvt00j367c_9w3d96w_y800000gn/T/ipykernel_9599/3258575506.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviews_df_updated['business_id'] = movie_list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating NPR...\n"
     ]
    }
   ],
   "source": [
    "PA_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['PA'])\n",
    "# FL_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['FL'])\n",
    "# TN_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['TN'])\n",
    "# IN_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['IN'])\n",
    "# MO_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['MO'])\n",
    "# LA_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['LA'])\n",
    "# AZ_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['AZ'])\n",
    "# NJ_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['NJ'])\n",
    "# NV_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['NV'])\n",
    "# AB_Restaurent_Recommendation = Recommendations(restaurent_state_df_map['AB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sankalp/Documents/Sankalp/study/Masters/Masters - Texas A&M/sems/sem 2/Courses/Info/project/Travelix/travelix.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPA_Restaurent_Recommendation.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(PA_Restaurent_Recommendation, file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mObject successfully saved to PA_Restaurent_Recommendation.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('PA_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "    pickle.dump(PA_Restaurent_Recommendation, file)\n",
    "print(\"Object successfully saved to PA_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('FL_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(FL_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to FL_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('TN_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(TN_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to TN_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('IN_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(IN_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to IN_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('MO_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(MO_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to MO_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('LA_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(LA_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to LA_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('AZ_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(AZ_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to AZ_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('NJ_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(NJ_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to NJ_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('NV_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(NV_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to NV_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('AB_Restaurent_Recommendation.pkl', 'wb') as file:\n",
    "#     pickle.dump(AB_Restaurent_Recommendation, file)\n",
    "# print(\"Object successfully saved to AB_Restaurent_Recommendation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non personalized recommendations for User 0:\n",
      "Rank 1: Business 273 - Name: Philadelphia International Airport - PHL - state: PA - stars: 2.5  - Popularity 5718.0\n",
      "Rank 2: Business 830 - Name: Gate 1 Travel - state: PA - stars: 3.5  - Popularity 3005.0\n",
      "Rank 3: Business 9 - Name: Kimpton Hotel Monaco Philadelphia - state: PA - stars: 4.0  - Popularity 2057.0\n",
      "Rank 4: Business 459 - Name: Philadelphia Marriott Downtown - state: PA - stars: 3.0  - Popularity 1871.0\n",
      "Rank 5: Business 726 - Name: Kimpton Hotel Palomar Philadelphia - state: PA - stars: 4.0  - Popularity 1867.0\n"
     ]
    }
   ],
   "source": [
    "PA_Hotel_Recommendation.getNPRForuUser(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/sankalp/Documents/Sankalp/study/Masters/Masters - Texas A&M/sems/sem 2/Courses/Info/project/Travelix/travelix.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPA_Restaurent_Recommendation.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     PA_Restaurent_Recommendation \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalp/Documents/Sankalp/study/Masters/Masters%20-%20Texas%20A%26M/sems/sem%202/Courses/Info/project/Travelix/travelix.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mObject successfully loaded from PA_Restaurent_Recommendation.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('PA_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "    PA_Restaurent_Recommendation = pickle.load(file)\n",
    "print(\"Object successfully loaded from PA_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('FL_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     FL_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from FL_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('TN_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     TN_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from TN_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('IN_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     IN_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from IN_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('MO_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     MO_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from MO_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('LA_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     LA_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from LA_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('AZ_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     AZ_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from AZ_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('NJ_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     NJ_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from NJ_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('NV_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     NV_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from NV_Restaurent_Recommendation.pkl\")\n",
    "\n",
    "# with open('AB_Restaurent_Recommendation.pkl', 'rb') as file:\n",
    "#     AB_Restaurent_Recommendation = pickle.load(file)\n",
    "# print(\"Object successfully loaded from AB_Restaurent_Recommendation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_implicit:\n",
    "    def __init__(self, train_mat, latent=5, lr=0.01, reg=0.01):\n",
    "        self.train_mat = train_mat  # the training rating matrix of size (#user, #movie)\n",
    "        \n",
    "        self.latent = latent  # the latent dimension\n",
    "        self.lr = lr  # learning rate\n",
    "        self.reg = reg  # regularization weight, i.e., the lambda in the objective function\n",
    "        \n",
    "        self.num_user, self.num_movie = train_mat.shape\n",
    "        \n",
    "        self.sample_user, self.sample_movie = self.train_mat.nonzero()  # get the user-movie paris having ratings in train_mat\n",
    "        self.num_sample = len(self.sample_user)  # the number of user-movie pairs having ratings in train_mat\n",
    "\n",
    "        # self.user_test_like = []\n",
    "        # for u in range(self.num_user):\n",
    "        #     self.user_test_like.append(np.where(self.test_mat[u, :] > 0)[0])\n",
    "\n",
    "        self.P = np.random.random((self.num_user, self.latent))  # latent factors for users, size (#user, self.latent), randomly initialized\n",
    "        self.Q = np.random.random((self.num_movie, self.latent))  # latent factors for users, size (#movie, self.latent), randomly initialized\n",
    "        \n",
    "    def negative_sampling(self):\n",
    "        negative_movie = np.random.choice(np.arange(self.num_movie), size=(len(self.sample_user)), replace=True)\n",
    "        true_negative = self.train_mat[self.sample_user, negative_movie] == 0\n",
    "        negative_user = self.sample_user[true_negative]\n",
    "        negative_movie = negative_movie[true_negative]\n",
    "        return np.concatenate([self.sample_user, negative_user]), np.concatenate([self.sample_movie, negative_movie])\n",
    "\n",
    "    def train(self, epoch=20):\n",
    "        \"\"\"\n",
    "        Goal: Write your code to train your matrix factorization model for epoch iterations in this function\n",
    "        Input: epoch -- the number of training epoch \n",
    "        \"\"\"\n",
    "        for ep in range(epoch):\n",
    "            \"\"\" \n",
    "            Write your code here to implement the training process for one epoch, \n",
    "            at the end of each epoch, run self.test() to evaluate current version of MF.\n",
    "            \"\"\"\n",
    "            print(\"Epoch:\", ep+1)\n",
    "            s_user, s_movie_i = self.negative_sampling()\n",
    "            data = np.column_stack((s_user, s_movie_i))\n",
    "            np.random.shuffle(data)\n",
    "            for u, i  in zip(data[:, 0], data[:, 1]):\n",
    "              actual_rating = self.train_mat[u, i]\n",
    "              pu = self.P[u, :]\n",
    "              qi = self.Q[i, :]\n",
    "\n",
    "              predicted_rating = np.dot(pu, qi)\n",
    "              error = 2*(predicted_rating-actual_rating)\n",
    "\n",
    "              grad_Pu = error * qi + 2*self.reg * pu\n",
    "              grad_Qi = error * pu + 2*self.reg * qi\n",
    "\n",
    "              self.P[u, :] -= self.lr * grad_Pu\n",
    "              self.Q[i, :] -= self.lr * grad_Qi\n",
    "            self.predict()\n",
    "\n",
    "            \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Write your code here to implement the prediction function, which generates the ranked lists of movies \n",
    "        by the trained MF for every user, store the result (named 'recommendation') in a numpy array of size (#user, 50), where entry (u, k) \n",
    "        represents the movie id that is ranked at position k in the recommendation list to user u. Return the 'recommendation' variable. \n",
    "        \"\"\"\n",
    "        prediction_mat = np.matmul(self.P, self.Q.T)\n",
    "        recommendation = []\n",
    "        for u in range(self.num_user):\n",
    "          scores = prediction_mat[u]\n",
    "          train_like = np.where(self.train_mat[u, :] > 0)[0]\n",
    "          scores[train_like] = -9999\n",
    "          top50_iid = np.argpartition(scores, -50)[-50:]\n",
    "          top50_iid = top50_iid[np.argsort(scores[top50_iid])[-1::-1]]\n",
    "          recommendation.append(top50_iid)\n",
    "        recommendation = np.array(recommendation)\n",
    "        return recommendation\n",
    "\n",
    "# MF_implicit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n"
     ]
    }
   ],
   "source": [
    "mf_implicit = MF_implicit(ratings_mat, latent=5, lr=0.01, reg=0.0001)\n",
    "mf_implicit.train(epoch=20)\n",
    "recommendation = mf_implicit.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627 532 290 555 452 535 293 468   6 455 376 701 534   4 715 606 475 702\n",
      "  540  14 245 700  12 315 730 100 331 660   5 296  90  34 308 242 246 371\n",
      "  717  20 394 297 161  32 447  45  88 536 400 178 257 727]\n",
      " [173 555 701  18  92 468 242 246 532   6 378 452 370 538 266 367 102 297\n",
      "  727 633 702 376 657   9  88  12 738 486  93 178  26 542 749 466 447 329\n",
      "  553 203  19  25 397 539 655 125 301 545 573 733 440   5]\n",
      " [161 297  14 245 327 376 535 455  98 627 454  12   6 475 660 555 622  45\n",
      "  290 181  20 252 246 148 676 291 533 337 628   5   4 532 300 466 283 705\n",
      "  331 569 452 416 702 394 447 629 536 277 271 408 655 738]\n",
      " [627 290 376 535 532 555 455 297   6  12  14 161 245 452 702  20   4 454\n",
      "  660 331  98 246   5  45 701 468 394 466 242 327 315 100 181 534 447 375\n",
      "  293 622 676 536 727 148 540 178 533 715   0 291 296 606]\n",
      " [449 701 468 532  92  88 452 555 713 251 397 702  18 235 728 172 367 242\n",
      "  634 659 654   6 542 293 776 716 711  10 389 453 600 373 173 266 175  25\n",
      "    3 657 179 540 246 112  29 538 440 257 480 378 488 703]\n",
      " [627 535 181 161 475 532 292 245   4  12 452 622 702  32   5 371 291   6\n",
      "    0 456 536 327  14 293 555 705 376 660 455  36 447 534 629 712 252 290\n",
      "  628 606 277 533  98 717 394 458 184 100  90 540 701 368]\n",
      " [452 532 701 546 702   4 447   6 555  89 301  88  95 371 293  12 246 235\n",
      "  545 161 243 540 606 292  92 368 738 717 622 705  90  14 465 630 178 397\n",
      "  173  32 456 389 309  86 187 468 245 538 373 382 634  17]\n",
      " [715 468 290 627 532 555 308 700 455 331 296 730   0 701 376  14  34 242\n",
      "  400 452 535 606 776 727 540 534 293 648 362 297  20 485 709 660 129 369\n",
      "    4 100 245  45 475 378 246 348 424 251 676 539 367 702]\n",
      " [452 532 465  91  88 701 546 243 449 293  90 397 309  89 235 702 371 634\n",
      "   29 389 373 630 241   3  95 716   4 179 721 162 447 299 187 713  92   5\n",
      "  188 621 340 368 473 606 540 659 703 301 555 720 542   6]\n",
      " [700   0 730 709 308 627 715 300 606  14 245 532 776 296 187  95 316  34\n",
      "  660 455 540 369 262 701   4 621 545 400 717 129 424 535 183 485  29 534\n",
      "  237 293 459  90 238 315 452  36 555 362 425 364 468  24]\n",
      " [701 452 555 173 532 545   6 738 246  95 301  14 546 447   5   4  89 161\n",
      "  702  86 106 538 177 633  92  12 397 639  88 549 297  39 178 468 376 622\n",
      "  235 542 382 540 300 245 283 645 733 709 731 308  18 606]\n",
      " [627 475 469 290 620 535 293 534 321 458 472 181 184 532 536 241 371 100\n",
      "  156 702  90 292 712 713   0 640 704 257 544  12 737 365 375 313 381  40\n",
      "  452 741 315 361  32 651 387 247 660 606   4 455 303 425]\n",
      " [702 532 555 452  12 701   6  92  88 705 246 447 468 173 370 376   5 242\n",
      "  178 301   4 600 657  26 293 466 533 655 257 297 235  18 538 329 704 375\n",
      "  703  98 367 546 102 738 727 540  11 486  89 378 749 290]\n",
      " [301 452 705 702 447 173 546 701  12 532   6   5 555 738 246  89  88  17\n",
      "  161  92   4 538 329 633 373 370 448 533 178 657 457 731 177 622 283 368\n",
      "  389 704 376 542  14 292 478   1 630  47 253 243 371 235]\n",
      " [701 545  95   9 532 555 452 549 308 397 173 468   6 106 709  86 246 621\n",
      "   14 546 776   4 716  29  92 488 235  89 258 700 733 738  39 367 542 447\n",
      "   88 379 129  25 378 553 728 715 538 459 183 564 440 175]\n",
      " [705 702 303 370 533 532 452 555  88 704  92   6 376 600 447  98 375   5\n",
      "  703 655  26 257 466 246  11 167 329 242 701 301 103 178 448 657 290 629\n",
      "  252 468 479 173   3 328 250 109  87 253 293  17 475 121]\n",
      " [452 532 702 701  88 447 555   5   6   4 293 371 546 301 705  89  92 235\n",
      "  465 292 368 704 246  90 540 243   3 178 606 468 600 703 241 717 389 373\n",
      "   32 630 309  17 713  91  95 161 449 456 625 376 622 257]\n",
      " [532 701 452 555   4 702 468   5  88 447 293 246 540  95 606 545 235  92\n",
      "   12  14  89 546 178 376   9 308 301 717 187 173 371  90 161  86 738 700\n",
      "   29 245 621 715 367 397 106 368 243 242 730  18 622 716]\n",
      " [532 555 452 702   6 701 246 447   5 376 705   4  88  92 173 468 161 297\n",
      "  301 178  14 370 242 293 533  98 738 466 540 535 655 235 371  89 629 622\n",
      "  245  11 290 454 546 704 455 368 102 600 257 731 375 292]\n",
      " [532 452 701 702 293 371 555   5   6  88 447  90 606  12 540 292 717  32\n",
      "  235 368  89 456 246 546 301 468 161  95   0 622 534 187 535 627  92 178\n",
      "  465 704 241 243 245  14 705   3 376 651  91  36 309 713]\n",
      " [468 449 713  88  92 532 702 251 172 452 701 600   3 242 257 167 703 293\n",
      "   18 235 708 370 659 387 711 367   6 749 510 241  12  26 657 375 728 654\n",
      "  259 666 372 373 727 178 205 290 634 776 540 376 254 465]\n",
      " [  0   4 532 452 456 371 292  32  90 606 293 717 245 622 161   5  36 700\n",
      "  627 701 535   6 540 447 291 702 300  14 651 730  95 181 712 555 534 368\n",
      "  187 469  89  12 142 628 364 327 176 301  88 546 551 235]\n",
      " [452 532 701   4  95 546   5  89 447 555 702  88 293 545 301 371 606 235\n",
      "  540 717  90 243 246 187 161  12 292 397 368 622  14  32 456  29 309 465\n",
      "  630  86  92 738  91 621 178 551 106 389 245 183 382 634]\n",
      " [532 452 555  88  12 701 468   6  92 293 376 447   5 705 257 246   4 242\n",
      "  600 713 178 370 290 235 704   3 540 371 375 703 466 167 368 251 606  26\n",
      "  534 449 535 241 533 627 367 655 301 727  90  18 172 173]\n",
      " [292 546 371 301 452  89 456  17 622   5   4 161 447 705  32 630 465 481\n",
      "  368   7 142 309 532 243 702 717  91  90 704  95 701 363 165 168 478  12\n",
      "  181   6 293  88 625  66  36 494 629  51 291 333 738 245]\n",
      " [705 702 452 301  12  88  17 447 532  92 546 704   5 373 370   6 555 701\n",
      "  329 173 303 703 533 600 657  89 253 246 448 538 465 389 368 738   4  26\n",
      "  371 121 178 479 457 292 328 333 481  87 630 243 625 670]\n",
      " [701 532 452 555   6 702 468  88 246 447  92   4   5 173  12 545 235 546\n",
      "  293 301  95  89 178  14 376   9 738 606 397  18 538 367 242  86 308 542\n",
      "  161 378 449 371 633 106 389 717 243 297 187 370 634 368]\n",
      " [452 301 532 546   5 447 702 292   4 371 705  89 701 161  12   6 622 368\n",
      "   88 456 465  32 555 243 293 704 630  15 481 309 717 246  90 738  95   7\n",
      "  235 629 606 625 478 540  91 245 142 181  11 373 389  92]\n",
      " [452 701 532  95 546  89 545 397   4  29 243  88 187 293 235  90  91 621\n",
      "  606 555   6 716 309 702 540 371 465 301 717 634 551 630  86 549 641 299\n",
      "  183 751 179 106 340   7 449 363  39 542  92 246 373 382]\n",
      " [468 532 555 702 701 242  92 452  88   6  12 376  18 370 246 290 727 257\n",
      "  367 713 251 173 375 293 178 378 466 600 447 449 235  26 749 331 715 540\n",
      "  655 657   4 167 172 297 102 264 711 703   3 387 125 539]\n",
      " [555 701 173 532 452 468   6  92 702 246 242  12  88 376 370 447 378 297\n",
      "  367 178 538 727   5 102 657 266 738   9 633 301 466  26   4 235  14 486\n",
      "  655 329 542 749   1 546 545 553 540 705  93  19 449 539]\n",
      " [173 555 701 532 452   6 246  92 702  12 447 468 370 376  88 301 738 297\n",
      "  538 242   5  18 633 178 102 657 705 378 329 546 367 266  14   9   4  26\n",
      "    1 486 727 466 283 655  89 542  93 177 731 545 161 235]\n",
      " [532 452 701 702 555   6  88 468 447  92   5 293   4 246 235 540 376 178\n",
      "  371 301 606  89 705 546 173 242 600 257 368 713  90 370   3 704  14 449\n",
      "  367 717 703 292  18  95 243 161 534 465 538 738 251 545]\n",
      " [ 90   0 293 532 627 651 469 156 606 620 472 534 371 361 241 713 640 452\n",
      "   29 187 730 540 425 717 716  13   3 708  91   4 477 299 776 176  32 458\n",
      "  621  36 619 377 413 456 700 292 715 118 701 387 535 702]\n",
      " [702  88 452 532 465   3 293 241 371 704 703 701 600  92  90 449 235   5\n",
      "  368 243 546  91 372 292 373 555 313 625 162   4   6  89 309 301  17 257\n",
      "  172 333 630 167  27   7 540 723 721 469 318 725 522 634]\n",
      " [173 555 701   6 246 297 532 452  14 738   9 376  12 447 702  92 468 545\n",
      "  301 633 102   5 161 242 538 378 283 178 177   4 370 569 727 367 731  88\n",
      "  546 266 645  19 466  86  89   1  93 657 639  95 106 655]\n",
      " [292 371 469 704 465 241  90 452 702 705 456 368 532  32 333  91 625 313\n",
      "    3 181 309  17  99  88 447 481 712 723 243  15  12 294 546  43 556 717\n",
      "   89 630 115 142 162 301 651 703 458 170 725 622 303  36]\n",
      " [549 397  95 545 546  39 106 179  86 340  89 363 639 398 542   9 551 733\n",
      "  641 382 621 634 258 275 751 630  29 389 183 709 738  21 716 701 564  46\n",
      "  410 373 301  66 403 177 694 299 309 538 173 380  37 379]\n",
      " [532  14 555 701 452   6 700 245 627 161 376 455 535   0 606 468 297 246\n",
      "    5 300 540 730 308 715 702 293  12 709 447 290 622 660 545 717 534 296\n",
      "    9 331 676  95 315 475  45 178 327  32 454 242  34  20]\n",
      " [546 452  89  95 532 701   4 301 243 371   5 447 309 630 465  91 292   7\n",
      "   90 702  88 456 545 717 293 368 397   6 363  32 235 622 606 187 551  17\n",
      "  389 161 555 540  29 634 382 168 751 373  86 340 142 738]\n",
      " [555 532 376   6 468 452 290 701 702  12 297 242 246 455  14 627 331   4\n",
      "  535 727   5 466 447  92 178 375 293  88 715 475 454 540 161  98 378 655\n",
      "  173 245 370  18 367 257  45 534 606 539 102 315 705 296]\n",
      " [546  17 397 373 301  89 630 389 243 465 179 340   7 309 542 634  15 398\n",
      "   39 452  95 363 457  91 538 447 701 738 168  66  88 188  86  23 656 481\n",
      "  382   5 705 549 545 173 467 522 702 207 368 253   1 235]\n",
      " [468 532 290 242 555 702 376 452 375 701  92 727 713  88 251 257   6  12\n",
      "  331 715  18 466 367 370 378 387 627 246 600 178 540 711 455 167 655 534\n",
      "  666 264 475 235 172   3 449 297 539 125  26 749 647 550]\n",
      " [  0 456 292  32 371 622  90  36 717 452 161  13 245 700 606 532 293 142\n",
      "    5 300  95 291 651 712 181 730 187 447 627 469  89 368 540 535  14 701\n",
      "  551 364  91 628   6 546 309 176 702 619 183   7 751 534]\n",
      " [701 555 468 532 173   6   9 452 242 308 246 378 545  14 715 297 727 367\n",
      "  376  92 648  25 129 488  95 702 709 776 331 102 540 539 178   4 295 106\n",
      "   88 447 738   5 553 266  86  12 125 235 455 175 700 633]\n",
      " [532 701 555 468 452   6  14 308 715 246 376   4   9 700 545 540 242 297\n",
      "  606 702 455 709   5 727 293  95 378 730 245 447 367 173  12 331 178 290\n",
      "   92 776 129 296  88 648 161 300 235 627 535 295   0  34]\n",
      " [532 468 452 293 702 713  88 701 555 251   3  92 257   6  90 540  12 235\n",
      "  241 290 449 387 242 600 371 708 627 376 715   5 447 178 703 472 375 776\n",
      "  167 704 246 156 367 666 313 535 361 711 737  10 321 727]\n",
      " [161 245 300 700 622 297   6   4 327 532 452 701   5 535 246 455 628 376\n",
      "  545 291 738 709 447   0 660  12 627 676  32  95   9 730 606 454 456 301\n",
      "   45 717 639 283 148 364 702  36 540  33 181 316 217 569]\n",
      " [532 452  90 293 371   4 606 292 456  32 717 627 701   5 540  36 651 700\n",
      "   13 702 187 730 245   6 534 622 469 535 447  95 555 161 368 712  88  91\n",
      "   29 241 291 235 176  14  89  12 300 181 619 551 361 309]\n",
      " [452 702 705  12   5 301 555 701  88   4 161 546 292  89 371  92 704 533\n",
      "   17 368 173 738  11 622 178 376 293 629 303 370 448 252 235  98 600 329\n",
      "   14 538 481 465  32 703 540 731 243 478 657 373 456  15]]\n"
     ]
    }
   ],
   "source": [
    "print(recommendation[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Autoencoder for recommendation(basic, top-10 recommendation for each user)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "ratings_mat_sparse = csr_matrix(ratings_mat)\n",
    "\n",
    "# load data\n",
    "#ratings = np.loadtxt('ratings.csv', delimiter=',')\n",
    "n_users, n_items = ratings_mat_sparse.shape\n",
    "\n",
    "# split data into training and validation sets\n",
    "split = int(0.8 * n_users)\n",
    "train_ratings = ratings_mat_sparse[:split]\n",
    "val_ratings = ratings_mat_sparse[split:]\n",
    "\n",
    "# define the autoencoder model\n",
    "input_layer = tf.keras.layers.Input(shape=(n_items,))\n",
    "encoded_layer = tf.keras.layers.Dense(16, activation='relu')(input_layer)\n",
    "decoded_layer = tf.keras.layers.Dense(n_items, activation='sigmoid')(encoded_layer)\n",
    "autoencoder = tf.keras.models.Model(input_layer, decoded_layer)\n",
    "\n",
    "# compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the model\n",
    "autoencoder.fit(train_ratings.toarray(), train_ratings.toarray(), epochs=20, batch_size=32, validation_data=(val_ratings, val_ratings))\n",
    "\n",
    "# predict ratings for all users and items\n",
    "predicted_ratings = autoencoder.predict(ratings_mat_sparse)\n",
    "\n",
    "# print top 10 recommended items for each user\n",
    "for i in range(n_users):\n",
    "    top_items = np.argsort(predicted_ratings[i])[::-1][:10]\n",
    "    print(f\"User {i+1}: {top_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48a9194367956c9607f494d6809ea58a846b01fefe7fdc109363ac5be64d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
